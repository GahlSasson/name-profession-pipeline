name: Discovery (Manual)

on:
  workflow_dispatch:
    inputs:
      clusters:
        description: "Space-separated clusters (e.g. 'Trades Arts Law Medicine Agriculture')"
        required: true
        default: "Trades"
      limit:
        description: "Max results per occupation query"
        required: true
        default: "60"
      langs:
        description: "Languages for labels (comma-separated, e.g. en,de,fr)"
        required: true
        default: "en"
      mode:
        description: "open (surname filter only) or strict (adds occupation filter)"
        required: true
        default: "open"

jobs:
  run:
    runs-on: ubuntu-latest
    env:
      PYTHONUNBUFFERED: "1"

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install pandas SPARQLWrapper rapidfuzz Metaphone requests

      - name: Show chosen inputs
        run: |
          echo "clusters: ${{ inputs.clusters }}"
          echo "limit:    ${{ inputs.limit }}"
          echo "langs:    ${{ inputs.langs }}"
          echo "mode:     ${{ inputs.mode }}"

      # Quick sanity: confirm your SPARQL template has placeholders
      - name: Show SPARQL template header
        run: |
          echo "First 30 lines of queries/query_template.sparql:"
          sed -n '1,30p' queries/query_template.sparql
          echo "----"
          echo "Looking for required placeholders:"
          (grep -n "{SURNAME_FILTER}" queries/query_template.sparql && echo "✓ SURNAME_FILTER found") || (echo "✗ SURNAME_FILTER MISSING"; exit 1)
          (grep -n "{OCCUPATION_FILTER}" queries/query_template.sparql && echo "✓ OCCUPATION_FILTER found") || (echo "✗ OCCUPATION_FILTER MISSING"; exit 1)

      # Run the discovery script – writes data/candidates_raw.csv when matches are found
      - name: Run discovery
        run: |
          set -e
          mkdir -p data
          echo "Running discovery…"
          python scripts/wikidata_nomen_agent.py \
            --mode "${{ inputs.mode }}" \
            --clusters ${{ inputs.clusters }} \
            --limit ${{ inputs.limit }} \
            --langs "${{ inputs.langs }}" \
            --outfile data/candidates_raw.csv

      # Always show what was produced
      - name: Debug output (if any)
        if: ${{ always() }}
        run: |
          echo "Data dir contents:"; ls -l data || true
          echo "CSV line count:";    wc -l data/candidates_raw.csv || true
          echo "First 5 lines:";     head -n 5 data/candidates_raw.csv || true

      - name: Save CSV as artifact
        if: ${{ hashFiles('data/candidates_raw.csv') != '' }}
        uses: actions/upload-artifact@v4
        with:
          name: discovery-csv
          path: data/candidates_raw.csv

      # Push to Airtable only when a CSV exists
      - name: Upload to Airtable (only if CSV exists)
        if: ${{ hashFiles('data/candidates_raw.csv') != '' }}
        env:
          AIRTABLE_API_KEY: ${{ secrets.AIRTABLE_API_KEY }}
          AIRTABLE_BASE_ID: ${{ secrets.AIRTABLE_BASE_ID }}
          AIRTABLE_TABLE_NAME: ${{ secrets.AIRTABLE_TABLE_NAME }}
        run: |
          echo "Using base: $AIRTABLE_BASE_ID ; table: $AIRTABLE_TABLE_NAME"
          python scripts/push_to_airtable.py --csv data/candidates_raw.csv

      - name: No CSV produced (read this hint)
        if: ${{ hashFiles('data/candidates_raw.csv') == '' }}
        run: |
          echo "No CSV produced. Check the 'Run discovery' step logs for [FILTER] lines."
          echo "If you see SPARQL rate limits (HTTP 429/504), re-run with a smaller limit (e.g. 30) and langs='en'."
          echo "If you see 'QueryBadFormed', your template must contain {SURNAME_FILTER} and {OCCUPATION_FILTER} placeholders."
