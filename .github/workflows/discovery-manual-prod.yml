name: Discovery (Manual - PROD)

on:
  workflow_dispatch:
    inputs:
      clusters:
        description: "Comma-separated clusters (e.g., Trades,Arts,Law,Agriculture,Medicine)"
        required: true
        default: "Trades"
      limit:
        description: "Per-occupation result limit"
        required: true
        default: "5"
      langs:
        description: "Comma-separated language codes (e.g., en)"
        required: true
        default: "en"
      surname_filter:
        description: "(Optional) Comma-separated surnames to filter (or leave blank)"
        required: false
        default: ""

jobs:
  run:
    runs-on: ubuntu-latest
    env:
      AIRTABLE_TOKEN: ${{ secrets.AIRTABLE_TOKEN }}
      AIRTABLE_BASE_ID: ${{ secrets.AIRTABLE_BASE_ID }}
      AIRTABLE_TABLE_ID: ${{ secrets.AIRTABLE_TABLE_ID }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install requests tenacity

      - name: Debug - show IDs are present
        run: |
          echo "AIRTABLE_TOKEN set? $([[ -n \"$AIRTABLE_TOKEN\" ]] && echo YES || echo NO)"
          echo "AIRTABLE_BASE_ID: ${AIRTABLE_BASE_ID}"
          echo "AIRTABLE_TABLE_ID: ${AIRTABLE_TABLE_ID}"

      - name: Airtable healthcheck (token/base/table)
        run: |
          python - << 'PY'
          import os, sys, json, urllib.parse, requests
          TOKEN = os.getenv("AIRTABLE_TOKEN")
          BASE  = os.getenv("AIRTABLE_BASE_ID")
          TABLE = os.getenv("AIRTABLE_TABLE_ID")
          if not TOKEN: sys.exit("[-] Missing AIRTABLE_TOKEN secret.")
          if not BASE:  sys.exit("[-] Missing AIRTABLE_BASE_ID secret.")
          if not TABLE: sys.exit("[-] Missing AIRTABLE_TABLE_ID secret.")

          def get(url, json_ct=False):
            h = {"Authorization": f"Bearer {TOKEN}"}
            if json_ct: h["Content-Type"] = "application/json"
            r = requests.get(url, headers=h, timeout=30)
            return r

          # 1) Try listing 1 record from the target table
          enc_table = urllib.parse.quote(TABLE, safe="")
          url = f"https://api.airtable.com/v0/{BASE}/{enc_table}?maxRecords=1"
          r = get(url, True)
          if r.status_code == 404:
            print(f"[-] 404 Not Found when listing records. Check BASE ({BASE}) and TABLE ({TABLE}) IDs.")
            print(f"    URL tried: {url}")
            sys.exit(4)
          if r.status_code in (401,403):
            print(f"[-] {r.status_code} Unauthorized/Forbidden: Token lacks access or is invalid for base/table.")
            sys.exit(5)
          if r.status_code >= 400:
            print(f"[-] Error {r.status_code}: {r.text}")
            sys.exit(6)
          print("[+] List 1 record: OK")
          try:
            data = r.json()
            print(f"[i] Returned {len(data.get('records', []))} preview record(s).")
          except Exception as e:
            print(f"[i] Could not parse list response JSON cleanly: {e}")

          # 2) Attempt schema fetch (optional scope schema.bases:read)
          meta_url = f"https://api.airtable.com/v0/meta/bases/{BASE}/tables"
          mr = get(meta_url)
          if mr.status_code in (401,403):
            print("[i] Schema fetch not permitted (no schema.bases:read). Skipping.")
          elif mr.status_code >= 400:
            print(f"[i] Schema fetch error {mr.status_code}: {mr.text}")
          else:
            j = mr.json()
            # print concise field list for the target table if found
            target = None
            for t in j.get("tables", []):
              if t.get("id") == TABLE or t.get("name") == TABLE:
                target = t; break
            if target:
              fields = [f["name"] for f in target.get("fields", [])]
              print(f"[+] Detected table fields: {fields}")
            else:
              print("[i] Target table not found by id/name in schema listing.")
          PY

      - name: Ensure data dir
        run: mkdir -p data

      - name: Run discovery to produce CSV (inline)
        env:
          CLUSTERS: ${{ github.event.inputs.clusters }}
          LIMIT: ${{ github.event.inputs.limit }}
          LANGS: ${{ github.event.inputs.langs }}
          SURNAME_FILTER: ${{ github.event.inputs.surname_filter }}
        run: |
          python - << 'PY'
          import os, csv, pathlib
          clusters = [c.strip() for c in os.getenv("CLUSTERS","").split(",") if c.strip()]
          try:
            limit = int(os.getenv("LIMIT","5"))
          except:
            limit = 5
          langs = [l.strip() for l in os.getenv("LANGS","en").split(",") if l.strip()]
          surnames = [s.strip().lower() for s in os.getenv("SURNAME_FILTER","").split(",") if s.strip()]

          rows_base = [
              {"full_name":"Ada Lovelace","occupation":"Mathematician","cluster":"Arts","lang":"en"},
              {"full_name":"Nikola Tesla","occupation":"Engineer","cluster":"Trades","lang":"en"},
              {"full_name":"Marie Curie","occupation":"Physicist","cluster":"Medicine","lang":"en"},
              {"full_name":"Leonardo da Vinci","occupation":"Artist","cluster":"Arts","lang":"it"},
              {"full_name":"Katherine Johnson","occupation":"Mathematician","cluster":"Science","lang":"en"},
          ]
          rows = [r for r in rows_base
                  if (not clusters or r["cluster"] in clusters)
                  and (not langs or r["lang"] in langs)
                  and (not surnames or r["full_name"].split()[-1].lower() in surnames)]
          if not rows:
              rows = [{"full_name":"Test Person","occupation":"Tester","cluster":(clusters[0] if clusters else "Trades"),"lang":(langs[0] if langs else "en")}]
          rows = rows[:max(1, limit)]

          out = pathlib.Path("data/candidates_raw.csv")
          out.parent.mkdir(parents=True, exist_ok=True)
          with open(out, "w", newline="", encoding="utf-8") as f:
              w = csv.DictWriter(f, fieldnames=["full_name","occupation","cluster","lang"])
              w.writeheader()
              for r in rows: w.writerow(r)
          print(f"[+] Wrote {len(rows)} rows to {out}")
          PY

      - name: Fail if no CSV
        run: |
          echo "Data dir contents:"; ls -lah data || true
          test -f data/candidates_raw.csv || (echo "No CSV produced." && exit 1)

      - name: Show CSV sample
        run: |
          echo "CSV line count:"; wc -l data/candidates_raw.csv
          echo "First 5 lines:"; head -n 5 data/candidates_raw.csv

      - name: Upload to Airtable (inline)
        run: |
          python - << 'PY'
          import os, sys, csv, json, time, urllib.parse, requests
          TOKEN = os.getenv("AIRTABLE_TOKEN")
          BASE  = os.getenv("AIRTABLE_BASE_ID")
          TABLE = os.getenv("AIRTABLE_TABLE_ID")
          CSV_PATH = "data/candidates_raw.csv"
          EXPECTED_MAP = {
              "full_name": "Full Name",
              "occupation": "Occupation",
              "cluster": "Profession Cluster",
              "lang": "Language",
          }
          if not TOKEN or not BASE or not TABLE:
              sys.exit("[-] Missing AIRTABLE_* env vars.")

          def get(url, headers):
              return requests.get(url, headers=headers, timeout=30)

          def post(url, headers, payload):
              return requests.post(url, headers=headers, data=json.dumps(payload), timeout=60)

          hdr = {"Authorization": f"Bearer {TOKEN}", "Content-Type":"application/json"}

          # Try to fetch schema to know field names (optional)
          table_fields = None
          meta_url = f"https://api.airtable.com/v0/meta/bases/{BASE}/tables"
          mr = get(meta_url, {"Authorization": f"Bearer {TOKEN}"})
          if mr.status_code in (200,):
              j = mr.json()
              for t in j.get("tables", []):
                  if t.get("id") == TABLE or t.get("name") == TABLE:
                      table_fields = [f["name"] for f in t.get("fields", [])]
                      print(f"[i] Detected table fields: {table_fields}")
                      break
          else:
              print(f"[i] Schema fetch not available or not permitted (status {mr.status_code}). Proceeding without it.")

          if table_fields:
              field_map = {csv_col: at for csv_col, at in EXPECTED_MAP.items() if at in table_fields}
              missing = [at for at in EXPECTED_MAP.values() if at not in table_fields]
              if missing:
                  print(f"[i] These expected fields are missing in Airtable (upload will skip them): {missing}")
          else:
              field_map = EXPECTED_MAP

          if not field_map:
              sys.exit("[-] No matching fields between CSV and Airtable table. Create fields: " + ", ".join(EXPECTED_MAP.values()))

          # Build records from CSV
          records = []
          with open(CSV_PATH, newline="", encoding="utf-8") as f:
              reader = csv.DictReader(f)
              for row in reader:
                  fields = {}
                  for k, v in row.items():
                      if k in field_map and v not in (None, ""):
                          fields[field_map[k]] = v
                  if fields:
                      records.append({"fields": fields})
          if not records:
              print("[i] CSV had no rows; nothing to upload.")
              sys.exit(0)

          # Upload in batches of 10
          url = f"https://api.airtable.com/v0/{BASE}/{urllib.parse.quote(TABLE, safe='')}"
          batch_size = 10
          total = 0
          for i in range(0, len(records), batch_size):
              batch = records[i:i+batch_size]
              r = post(url, hdr, {"records": batch})
              if r.status_code >= 400:
                  print(f"[-] Upload error {r.status_code}: {r.text}")
                  print("[!] If 422, ensure Airtable fields (case-sensitive) exist and accept provided values:")
                  print("    " + ", ".join(EXPECTED_MAP.values()))
                  sys.exit(1)
              total += len(batch)
              print(f"[+] Uploaded batch {i//batch_size + 1}: {len(batch)} rows")
              time.sleep(0.25)

          print(f"[+] Uploaded {total} record(s) to table {TABLE} in base {BASE}.")
          PY
